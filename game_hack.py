# -*- coding: utf-8 -*-
"""game_hack.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yJ3_2YxobI7mRdajI8a_A7drRotwbpC8

# Prisioners Dynamical System

This is a cadCAD implementation of a Generalized Dynamical Systems representation of the Repeated Prisioners Dilemma

Authors: Michael Zargham (zargham@block.science), Danilo Lessa Bernardineli (danilo@block.science) and Matt Stephenson (matt@block.science)
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # Install extra dependencies
# !pip install cadCAD-tools
# !pip install ipython-autotime
# !pip install holoviews
# !pip install hvplot
# !pip install hvnx
# 
# # Automatically print time
# %load_ext autotime

"""## Dependencies"""

# For running the cadCAD representation
from cadCAD_tools import easy_run
from cadCAD_tools.types import Param, ParamSweep
from cadCAD_tools.preparation import prepare_params

# For numerics & analytics
import pandas as pd
import numpy as np
import scipy.stats as st
import networkx as nx

# For visualizations
import plotly.express as px
import hvplot.networkx as hvnx
import holoviews as hv

"""## Model & simulation set-up"""

MONTE_CARLO_RUNS = 5
SIMULATION_TIMESTEPS = 500
N_AGENTS = 15
INITIAL_GOODWILL = 0.8


sys_params = {
    'coordinate_param': Param(10, float),
    'exploiter_param': Param(15, float),
    'exploited_param': Param(0, float),
    'defect_param': Param(2, float),
    'coordinate_goodwill': ParamSweep([1.2, 2.0], float),
    'exploiter_goodwill': ParamSweep([1.0], float),
    'exploited_goodwill': ParamSweep([0.4, 0.8], float),
    'defect_goodwill': ParamSweep([0.8, 1.2], float),
    'max_goodwill': Param(0.95, float),
    'min_goodwill': Param(0.05, float)
}

sys_params = prepare_params(sys_params, True)

genesis_states = {
    'goodwill': np.ones((N_AGENTS, N_AGENTS)) * INITIAL_GOODWILL,
    'decisions': np.ones((N_AGENTS, N_AGENTS)) * np.nan,
    'rewards': np.zeros(N_AGENTS)
    
}

@np.vectorize
def agent_choice(goodwill: float) -> float:
    return st.bernoulli.rvs(goodwill)

def get_payout(agent_index: int,
               counterparty_index: int,
               choices: list,
               params) -> float:        
        i = agent_index
        j = counterparty_index
        
        i_choice = choices[i][j]
        j_choice = choices[j][i]
        
        if (i_choice == 1.0) & (j_choice == 1.0):
            return params['coordinate_param']
        elif (i_choice == 1.0) & (j_choice == 0.0):
            return params['exploiter_param']
        elif (i_choice == 0.0) & (j_choice == 1.0):
            return params['exploited_param']
        elif (i_choice == 0.0) & (j_choice == 0.0):
            return params['defect_param']


def get_goodwill(agent_index: int,
               counterparty_index: int,
               choices: list,
               goodwill: float,
               params) -> float:        
        i = agent_index
        j = counterparty_index
        
        i_choice = choices[i][j]
        j_choice = choices[j][i]

        if (i_choice == 1.0) & (j_choice == 1.0):
            return np.clip(goodwill * params['coordinate_goodwill'], 
                           params['min_goodwill'], 
                           params['max_goodwill'])
        elif (i_choice == 1.0) & (j_choice == 0.0):
            return np.clip(goodwill * params['exploiter_goodwill'], 
                           params['min_goodwill'], 
                           params['max_goodwill'])
        elif (i_choice == 0.0) & (j_choice == 1.0):
            return np.clip(goodwill * params['exploited_goodwill'], 
                           params['min_goodwill'], 
                           params['max_goodwill'])
        elif (i_choice == 0.0) & (j_choice == 0.0):
            return np.clip(goodwill * params['defect_goodwill'], 
                           params['min_goodwill'], 
                           params['max_goodwill'])


def p_agent_choices(params, step, sL, s):
    choices = agent_choice(s['goodwill'])
    return {'choices': choices}


def s_goodwill(params, _2, _3, prev_state, policy_input):
    choices = policy_input['choices']  
    N_agents = len(prev_state['goodwill'])
    old_goodwill = prev_state['goodwill']
    new_goodwill = prev_state['goodwill'].copy()
    for i in range(N_agents):
      for j in range(N_agents):
        if i == j:
          continue
        else:
          new_goodwill[i] = get_goodwill(i, j, choices, old_goodwill[i][j], params)
    return ('goodwill', new_goodwill)

def s_choices(params, 
                substep, 
                state_history, 
                prev_state, 
                policy_input):
    value = policy_input['choices']
    return ('decisions', value)


def s_rewards(params, 
                substep, 
                state_history, 
                prev_state, 
                policy_input):
    choices = policy_input['choices']  
    N_agents = len(prev_state['rewards'])
    rewards = prev_state['rewards'].copy()
    for i in range(N_agents):
      for j in range(N_agents):
        if i == j:
          continue
        else:
          rewards[i] += get_payout(i, j, choices, params)
    return ('rewards', rewards)


partial_state_update_blocks = [
    {
        'policies': {
           'decision_making': p_agent_choices
        },
        'variables': {
            'decisions': s_choices,
            'rewards' : s_rewards,
            'goodwill': s_goodwill
        }
    }
]

"""## Simulation & Analytics"""

df = easy_run(genesis_states, 
              sys_params, 
              partial_state_update_blocks,
              SIMULATION_TIMESTEPS,
              MONTE_CARLO_RUNS,
              assign_params=True)

df = (df.assign(mean_goodwill=lambda df: df.goodwill.map(lambda x: x.mean()))
        .assign(std_goodwill=lambda df: df.goodwill.map(lambda x: x.std()))
)

fig = px.line(df, 
              x='timestep',
              y='mean_goodwill', 
              facet_col='coordinate_goodwill',
              facet_row='exploited_goodwill',
              color='defect_goodwill',
              line_group='run') 
fig.update_traces(line=dict(width=1.0))
fig.show()

fig = px.line(df, 
              x='timestep',
              y='std_goodwill', 
              facet_col='coordinate_goodwill',
              facet_row='exploited_goodwill',
              color='defect_goodwill',
              line_group='run') 
fig.update_traces(line=dict(width=1.0))
fig.show()

# Commented out IPython magic to ensure Python compatibility.
# HACK for making it work with Google Colab
# %env HV_DOC_HTML=true
hv.extension('bokeh')

G = nx.from_numpy_matrix(df.goodwill[15])

options = {'with_labels': True,
           'edge_width': 'weight',
           'edge_color': 'weight'}

viz = hvnx.draw_circular(G, **options)

viz

# Commented out IPython magic to ensure Python compatibility.
# HACK for making it work with Google Colab
# %env HV_DOC_HTML=true
hv.extension('bokeh')

def plot_goodwill(timestep, 
                  coordinate_goodwill, 
                  exploited_goodwill, 
                  defect_goodwill,
                  run,
                  weight_scale=5.0,
                  node_scale=5e2):

  query = f"coordinate_goodwill == {coordinate_goodwill}"
  query += f" & exploited_goodwill == {exploited_goodwill}"
  query += f" & defect_goodwill == {defect_goodwill}"
  query += f" & run == {run}" 

  fig_df = df.query(query)
  G = nx.from_numpy_matrix(fig_df.goodwill.iloc[timestep],
                           True)
  N = len(G.nodes)

  for u in G.nodes:
    G.nodes[u]['size'] = 0.0
  
  for u, v, data in G.edges(data=True):
    weight = G[u][v]['weight'] * weight_scale
    G[u][v]['weight'] = weight 
    G.nodes[u]['size'] += node_scale * weight / (2 * N)
    G.nodes[v]['size'] += node_scale * weight / (2 * N)
  

  options = {'with_labels': True,
             'node_size': 'size',
             'edge_color': 'weight',
             'edge_width': 'weight'}

  return hvnx.draw_circular(G, **options)

dims = {'timestep': df.timestep.unique(),
        'coordinate': df.coordinate_goodwill.unique(),
        'exploited': df.exploited_goodwill.unique(),
        'defect': df.defect_goodwill.unique(),
        'run': df.run.unique()}

dmap = hv.DynamicMap(plot_goodwill, kdims=list(dims.keys()))
dmap = dmap.redim.values(**dims)
dmap

